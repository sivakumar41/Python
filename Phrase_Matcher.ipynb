{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "353a3676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T05:05:15.832678Z",
     "start_time": "2023-10-06T05:05:10.720313Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "358c98d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T05:25:45.626054Z",
     "start_time": "2023-10-06T05:25:45.350032Z"
    }
   },
   "outputs": [],
   "source": [
    "import PyPDF2  #for reading the pdf file\n",
    "with open(\"SivaKumar_resume.pdf\", \"rb\") as file:\n",
    "    pdf_reader = PyPDF2.PdfReader(file)    #Object\n",
    "    num_pages = len(pdf_reader.pages)\n",
    "    data = \"\"\n",
    "    for page_num in range(num_pages):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        \n",
    "        data += page.extract_text()\n",
    "#print(data)\n",
    "doc=nlp(data)\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fb4c76c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T05:27:17.213467Z",
     "start_time": "2023-10-06T05:27:17.181462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 54 55\n",
      "Python 180 181\n",
      "CSS 192 193\n",
      "Python 276 277\n",
      "machine learning 307 309\n",
      "Python 317 318\n",
      "Python 330 331\n",
      "Python 427 428\n",
      "Python 493 494\n",
      "Python 533 534\n",
      "Python 580 581\n",
      "machine learning 600 602\n",
      "Python 605 606\n",
      "machine learning 688 690\n",
      "Python 706 707\n",
      "Python 796 797\n"
     ]
    }
   ],
   "source": [
    "#Phrase Matchers\n",
    "terms=[\"Python\",\"c\",\"java\",\"machine learning\",\"Data %%SVGcience\",\"html\",\"CSS\"] #these are the terms i want to extract for the resume\n",
    "pattern=[nlp.make_doc(term) for term in terms]\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher=PhraseMatcher(nlp.vocab)# creating the obj to the pharsematcher\n",
    "#now we need to add the pattern to the matcher\n",
    "matcher.add(\"Skills\",pattern)\n",
    "#now the marcher will act as the regular expression we can apply it to the doc \n",
    "match=matcher(doc)\n",
    "#print(match)\n",
    "\n",
    "#now iterate over the match and find the text and index\n",
    "for match_id,start,end in match:\n",
    "    print(doc[start:end].text,start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a10c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T05:06:04.983722Z",
     "start_time": "2023-10-06T05:06:04.547720Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
